/*
 * Softmax classifier layer.
 */
forward = function(matrix[double] scores) return (matrix[double] probs) {
  /*
   * Computes the forward pass for a softmax classifier.  The inputs
   * are interpreted as unnormalized, log-probabilities for each of
   * N examples, and the softmax function transforms them to normalized
   * probabilities.
   *
   * Inputs:
   *  - scores: Input data matrix, of shape (N, D).
   *
   * Outputs:
   *  - probs: Ouptuts, of shape (N, D).
   */
  unnorm_probs = exp(scores)
  probs = unnorm_probs / rowSums(unnorm_probs)
}

backward = function(matrix[double] dprobs, matrix[double] scores)
    return (matrix[double] dscores) {
  /*
   * Computes the backward pass for a softmax classifier.
   *
   * dprobs_ij/dscores_ij = probs_ij * (1 - probs_ij)
   * dprobs_ic/dscores_ij = probs_ij * -probs_ic
   *
   * dloss/dscores_ij = dloss/dprobs_ij * dprobs_ij/dscores_ij + 
   *                    sum_c(dloss/dprobs_ic * dprobs_ic/dscores_ij)
   *
   * Inputs:
   *  - dprobs: Derivatives from upstream, of shape (N, D).
   *  - scores: Previous input data matrix, of shape (N, D).
   *
   * Outputs:
   *  - dscores: Gradient wrt scores, of shape (N, D).
   */
  unnorm_probs = exp(scores)
  probs = unnorm_probs / rowSums(unnorm_probs)
  dscores = dprobs * probs
  dscores = dscores - probs * rowSums(dscores)
}

